{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# The Melting Pot of Berlin"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Introduction"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Have you ever asked yourself where currywurst was invented? The invention of currywurst is attributed to a woman called Herta Heuwer in Berlin in 1949, after she obtained ketchup and curry powder from British soldiers in Germany. She mixed these ingredients with other spices and poured it over grilled pork sausage. Heuwer started selling the cheap but filling snack at a street stand in the Charlottenburg district of Berlin, where it became popular with construction workers rebuilding the devastated city. Although, currywurst is the most popular and well-known food of Berlin, the city still can offer a lot more. Especially when it comes to international food, since it's the second home for more than million people with migration background. Therfore, it's somehow interesting to learn more about food in Berlin and how migration affects local food and traditional restaurants. \nIn the following notebook, we will analyze the impact of migration on local and traditional restaurants in Berlin based on the distribution of local restaurants around the city."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Therefor, we will use official data from the Statistical Office of Berlin-Brandenburg about registered residents with migration background which was published by the Federal State of Berlin in 2018. Moreover, we will be using data about the boroughs of Berlin, also published by the Federal State, in combination with Foursquare location data in order to learn more about local restaurants in Berlin. So let's get started!"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Code"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Download all dependencies that we will need."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: | "
                }
            ],
            "source": "import numpy as np # Library to handle data in a vectorized manner\n\nimport pandas as pd # Library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # Library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # Library to handle requests\nfrom pandas.io.json import json_normalize # Tranform JSON file into a pandas dataframe\n\nimport bs4 as bs\nfrom bs4 import BeautifulSoup as soup\n\nfrom urllib.request import urlopen as uReq\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# Import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes \nimport folium # map rendering library\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Download data about registered residents with migration background from csv-file."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "br_data = pd.read_csv(\"https://www.statistik-berlin-brandenburg.de/opendata/EWRMIGRA201812H_Matrix.csv\", sep=\";\")\nbr_data.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's take a look at the structure of the dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "print(\"The dataframe has {} rows and {} columns.\".format(br_data.shape[0], br_data.shape[1]))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's take a look at the data types of the columns."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "br_data.dtypes"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As you can see all columns contain data of type int."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's get a statistical summary of the data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "br_data.describe()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As you can see for some columns it's not that useful to determine descriptive statistics. So let's start cleaning the data by dropping all columns that we won't use in our analysis."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "br_data.drop([\"ZEIT\",\"RAUMID\", \"PGR\", \"BZR\", \"PLR\", \"STADTRAUM\", \"HK_EU15\", \"HK_EU28\", \"HK_Polen\", \"HK_EheJug\", \"HK_EheSU\", \"HK_Turk\",\"HK_Arab\", \"HK_Sonst\", \"HK_NZOrd\"], axis=1, inplace=True)\n\n# BEZ stands for the Admin. Nr. of the borough and MH_E for the total number of registered people with migration background. So let's rename them.\nbr_data.rename(columns={\"BEZ\": \"Ad. Nr.\", \"MH_E\":\"People with migration background\"}, inplace=True)\n\n# Sort values by Ad. Nr. in ascending order \nbr_data.sort_values(\"Ad. Nr.\", inplace=True)\n\n# Group data by Ad. Nr. and count the sum of people with migration background in each borough\nbr_data = br_data.groupby(\"Ad. Nr.\").sum()\nbr_data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, we need the official names of the boroughs. So let's download them by importing the following csv-file."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "brgh = pd.read_csv(\"https://tsb-opendata.s3.eu-central-1.amazonaws.com/bezirksgrenzen/bezirksgrenzen.csv\")\nbrgh.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As you can see, the dataframe needs some cleaning work."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Therefor, rename important columns, sort the data by Ad. Nr. in ascending order and set it as index."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "brgh.rename(columns={\"Gemeinde_schluessel\": \"Ad. Nr.\", \"Gemeinde_name\":\"Borough\"}, inplace=True)\nbrgh.sort_values(\"Ad. Nr.\", ascending=True, inplace=True)\nbrgh.reset_index(drop=True, inplace=True)\nbrgh.set_index(\"Ad. Nr.\", inplace=True)\nbrgh"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, we will merge both dataframes and set Ad. Nr. as index."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "brgh = brgh[[\"Borough\"]]\nbrgh[\"People with migration background\"] = br_data[\"People with migration background\"]\nbr_data = brgh\nbr_data"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "scrolled": true
            },
            "source": "Now, let's get geolocation data for each borough."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Import dependencies\nfrom geopy.extra.rate_limiter import RateLimiter \n\nlocator = Nominatim(user_agent=\"myGeocoder\")\nlocation = locator.geocode(\"Berlin, DE\")\n\n# Conveneint function to delay between geocoding calls\ngeocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n\n# Create location column\nbr_data['Location'] = br_data['Borough'].apply(geocode)\n\n# Create longitude, laatitude and altitude from location column (returns tuple)\nbr_data['Point'] = br_data['Location'].apply(lambda loc: tuple(loc.point) if loc else None)\n\n# Split point column into latitude, longitude and altitude columns\nbr_data[['Latitude', 'Longitude', 'Altitude']] = pd.DataFrame(br_data['Point'].tolist(), index=br_data.index)\nbr_data.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's drop unnecessary columns like Location, Point and Altitude."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "br_data.drop([\"Location\", \"Point\", \"Altitude\"], axis=1, inplace=True)\nbr_data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As you may have noticed, the latitude and longitude of Lichtenberg are obviously wrong. So let's correct them."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "location = \"Lichtenberg, Berlin, DE\"\n\ngeolocator = Nominatim(user_agent = \"br_explorer\")\nlocation = geolocator.geocode(location)\nlatitude = location.latitude\nlongitude = location.longitude\nprint(\"The geograpical coordinates of Lichtenberg are {}, {}.\".format(latitude, longitude))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, we have the right coordinates. Let's add them to our data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "br_data.loc[11,\"Latitude\"] = latitude\nbr_data.loc[11,\"Longitude\"] = longitude\nbr_data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "And there you have it, a nice dataframe with all the data we need."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In the **second step**, we will use Foursquare location data to learn more about local restaurants in Berlin."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's define Foursquare credentials and version."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "CLIENT_ID = \"HQHI11JH4DAVEGSIYZHDM4BA5DFETP3MQBXKJOSV4X3YX4RN\" # Foursquare ID\nCLIENT_SECRET = \"ITTCVGBQRSJVDQQDGPCJ3SDUG5FV5B1MHBGYRAYQJLH2DT0V\" # Foursquare Secret\nVERSION = \"20180605\" # Foursquare API version\n\nprint(\"Your credentails:\")\nprint(\"CLIENT_ID: \" + CLIENT_ID)\nprint(\"CLIENT_SECRET:\" + CLIENT_SECRET)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's explore the boroughs of Berlin. We can start with Berlin Mitte, since it's one of the largest boroughs in Berlin."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "br_loc = br_data.loc[1, \"Borough\"] # borough name\nbr_lat = br_data.loc[1, \"Latitude\"] # neighborhood latitude value\nbr_long = br_data.loc[1, \"Longitude\"] # neighborhood longitude value\n\nprint(\"Latitude and longitude values of {} are {}, {}.\".format(br_loc, br_lat, br_long))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, let's get the top 100 venues which are located in **Berlin Mitte**."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "radius = 5000 # Search radius in m\nsearch_query = 'venues' # Search query\nLIMIT = 100 # Results limit\nexp_url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET,\n                                                                                                                               br_lat, br_long,\n                                                                                                                               VERSION, radius, LIMIT)\nexp_url"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Send the GET request and examine the results."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "results = requests.get(exp_url).json()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, extract the category of the venues above in order to get restaurants data and clean the results."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def get_category_type(row):\n    try:\n        categories_list = row[\"categories\"]\n    except:\n        categories_list = row[\"venue.categories\"]\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0][\"name\"]\n    \nvenues = results[\"response\"][\"groups\"][0][\"items\"]\n\n# flatten JSON\nnearby_venues = json_normalize(venues)\n# filter columns\nfiltered_columns = [\"venue.name\", \"venue.categories\", \"venue.location.lat\", \"venue.location.lng\"]\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n# filter the category for each row\nnearby_venues[\"venue.categories\"] = nearby_venues.apply(get_category_type, axis=1)\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, we have a dataframe with all venues within a radius of 5000 m around **Berlin Mitte**. Let's take a look at it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "nearby_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, let's create a function to apply the same process on all boroughs."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=5000):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # Create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # Make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # Return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = [\"Borough\", \n                  'Borough Latitude', \n                  'Borough Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now write the code to run the above function on each borough, create a new dataframe and name it **br_venues**."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "br_venues = getNearbyVenues(names=br_data[\"Borough\"],\n                                   latitudes=br_data[\"Latitude\"],\n                                   longitudes=br_data[\"Longitude\"]\n                                  )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's check the size of the resulting dataframe and take a look at it."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(br_venues.shape)\nbr_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, let's filter our venues in order to get an extra dataframe for restaurants."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "idx = np.where((br_venues['Venue Category'].str.endswith('Restaurant')))\nbr_rest = br_venues.loc[idx]\nbr_rest.reset_index(drop=True, inplace=True)\nbr_rest.drop(\"Borough Latitude\",axis=1, inplace=True)\nbr_rest.drop(\"Borough Longitude\",axis=1, inplace=True)\nbr_rest.rename(columns={\"Venue\": \"Restaurant\", \"Venue Latitude\":\"Latitude\", \"Venue Longitude\":\"Longitude\", \"Venue Category\":\"Category\"}, inplace=True)\nprint(br_rest.shape)\nbr_rest.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's check how many restaurants were returned for each category."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "br_rest.groupby([\"Category\"]).count().head(15)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's find out how many unique categories can be curated from all the returned restaurants."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "print(\"There are {} unique categories.\".format(len(br_rest[\"Category\"].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In order to analyze local restaurants, let's filter the category \"German Restaurant\"."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "idx = np.where((br_rest['Category'].str.startswith('German'))) # Filter category \"German\"\nbr_rest_gr = br_rest.loc[idx]\nbr_rest_gr = br_rest_gr.groupby(\"Borough\").count() # Group by bourough name and count\nbr_rest_gr.reset_index(inplace=True) # Reset index\nbr_rest_gr.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, let's try to visulize both dataframes br_data and  br_rest_gr using folium and choropleth maps. Therefor, download geojson file for boroughs."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# download boroughs geojson file\n!wget --quiet https://tsb-opendata.s3.eu-central-1.amazonaws.com/bezirksgrenzen/bezirksgrenzen.geojson\nprint(\"Download completed.\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create a map of Berlin using folium."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "berlin_geo = r'https://tsb-opendata.s3.eu-central-1.amazonaws.com/bezirksgrenzen/bezirksgrenzen.geojson' # Read geojson file\nlat = 52.5\nlon = 13.42\n\n# Create map\nberlin_map1 = folium.Map(location=[lat, lon], zoom_start=10)\nberlin_map1"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, generate a choropleth map using the total number of registered people with migration background in Berlin."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# Generate choropleth map \nberlin_map1.choropleth(\n    geo_data=berlin_geo,\n    data=br_data,\n    columns=['Borough', 'People with migration background'],\n    key_on='feature.properties.Gemeinde_name',\n    fill_color='Blues', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='People with migration background in Berlin'\n)\n\nberlin_map1"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, let's create a new map of Berlin in order to visualize the distribution of local restaurants in Berlin."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# Create a new Berlin map\nberlin_map2 = folium.Map(location=[lat, lon], zoom_start=10)\nberlin_map2"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create choropleth map of German restaurants."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "berlin_map2.choropleth(\n    geo_data=berlin_geo,\n    data=br_rest_gr,\n    columns=['Borough', 'Restaurant'],\n    key_on='feature.properties.Gemeinde_name',\n    fill_color='Blues', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='German restaurants in Berlin'\n)\n\nberlin_map2"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "As you may have noticed when you compare both choropleth maps, boroughs with a high proportion of people with migration background have generally less local restaurants than boroughs with less proportion of people with migration background."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Final report"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Coming soon"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}